{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw8.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 8: Time series\n",
    "**Due date: See the [Calendar](https://htmlpreview.github.io/?https://github.com/UBC-CS/cpsc330/blob/master/docs/calendar.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions\n",
    "<hr>\n",
    "rubric={points:4}\n",
    "\n",
    "You will receive marks for correctly submitting this assignment. To submit this assignment, follow the instructions below:\n",
    "\n",
    "- **You may work on this assignment in a group (group size <= 4) and submit your assignment as a group.** \n",
    "- Below are some instructions on working as a group.  \n",
    "    - The maximum group size is 4. \n",
    "    - You can choose your own group members. \n",
    "    - Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "    - Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "    - It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. [Here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members) are some instructions on adding group members in Gradescope.  \n",
    "- Upload the .ipynb file to Gradescope.\n",
    "- **If the .ipynb file is too big or doesn't render on Gradescope for some reason, also upload a pdf or html in addition to the .ipynb.** \n",
    "- Make sure that your plots/output are rendered properly in Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: time series prediction\n",
    "\n",
    "In this exercise we'll be looking at a [dataset of avocado prices](https://www.kaggle.com/neuromusic/avocado-prices). You should start by downloading the dataset. We will be forcasting average avocado price for the next week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AveragePrice  Total Volume     4046       4225    4770  \\\n",
       "0 2015-12-27          1.33      64236.62  1036.74   54454.85   48.16   \n",
       "1 2015-12-20          1.35      54876.98   674.28   44638.81   58.33   \n",
       "2 2015-12-13          0.93     118220.22   794.70  109149.67  130.50   \n",
       "3 2015-12-06          1.08      78992.15  1132.00   71976.41   72.58   \n",
       "4 2015-11-29          1.28      51039.60   941.48   43838.39   75.78   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  region  \n",
       "0     8696.87     8603.62       93.25          0.0  conventional  2015  Albany  \n",
       "1     9505.56     9408.07       97.49          0.0  conventional  2015  Albany  \n",
       "2     8145.35     8042.21      103.14          0.0  conventional  2015  Albany  \n",
       "3     5811.16     5677.40      133.76          0.0  conventional  2015  Albany  \n",
       "4     6183.95     5986.26      197.69          0.0  conventional  2015  Albany  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/avocado.csv\", parse_dates=[\"Date\"], index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18249, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2015-01-04 00:00:00')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Date\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-03-25 00:00:00')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Date\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the data ranges from the start of 2015 to March 2018 (~2 years ago), for a total of 3.25 years or so. Let's split the data so that we have a 6 months of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = '20170925'\n",
    "df_train = df[df[\"Date\"] <= split_date]\n",
    "df_test  = df[df[\"Date\"] >  split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_train) + len(df_test) == len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.1 How many time series? \n",
    "rubric={points:4}\n",
    "\n",
    "In the Rain is Australia dataset from lecture, we had different measurements for each Location. What about this dataset: for which categorical feature(s), if any, do we have separate measurements? Justify your answer by referencing the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.22</td>\n",
       "      <td>40873.28</td>\n",
       "      <td>2819.50</td>\n",
       "      <td>28287.42</td>\n",
       "      <td>49.90</td>\n",
       "      <td>9716.46</td>\n",
       "      <td>9186.93</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1373.95</td>\n",
       "      <td>57.42</td>\n",
       "      <td>153.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1162.65</td>\n",
       "      <td>1162.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>435021.49</td>\n",
       "      <td>364302.39</td>\n",
       "      <td>23821.16</td>\n",
       "      <td>82.15</td>\n",
       "      <td>46815.79</td>\n",
       "      <td>16707.15</td>\n",
       "      <td>30108.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.76</td>\n",
       "      <td>3846.69</td>\n",
       "      <td>1500.15</td>\n",
       "      <td>938.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1408.19</td>\n",
       "      <td>1071.35</td>\n",
       "      <td>336.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.08</td>\n",
       "      <td>788025.06</td>\n",
       "      <td>53987.31</td>\n",
       "      <td>552906.04</td>\n",
       "      <td>39995.03</td>\n",
       "      <td>141136.68</td>\n",
       "      <td>137146.07</td>\n",
       "      <td>3990.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>BaltimoreWashington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1125443.38</td>\n",
       "      <td>116338.61</td>\n",
       "      <td>237876.77</td>\n",
       "      <td>1182.85</td>\n",
       "      <td>769536.90</td>\n",
       "      <td>639021.62</td>\n",
       "      <td>130401.43</td>\n",
       "      <td>113.85</td>\n",
       "      <td>organic</td>\n",
       "      <td>2017</td>\n",
       "      <td>TotalUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>1.59</td>\n",
       "      <td>3842682.36</td>\n",
       "      <td>1450858.85</td>\n",
       "      <td>1006684.68</td>\n",
       "      <td>42995.08</td>\n",
       "      <td>1342143.75</td>\n",
       "      <td>764285.55</td>\n",
       "      <td>575719.82</td>\n",
       "      <td>2138.38</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2017</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>2.40</td>\n",
       "      <td>111321.19</td>\n",
       "      <td>17650.08</td>\n",
       "      <td>22295.44</td>\n",
       "      <td>42.34</td>\n",
       "      <td>71333.33</td>\n",
       "      <td>40018.26</td>\n",
       "      <td>31209.23</td>\n",
       "      <td>105.84</td>\n",
       "      <td>organic</td>\n",
       "      <td>2017</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>1.22</td>\n",
       "      <td>584045.70</td>\n",
       "      <td>363596.75</td>\n",
       "      <td>99990.28</td>\n",
       "      <td>415.70</td>\n",
       "      <td>120042.97</td>\n",
       "      <td>68799.49</td>\n",
       "      <td>51236.81</td>\n",
       "      <td>6.67</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2017</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>2.26</td>\n",
       "      <td>9528.64</td>\n",
       "      <td>1545.34</td>\n",
       "      <td>2234.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5749.07</td>\n",
       "      <td>5722.40</td>\n",
       "      <td>26.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>2017</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15441 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  AveragePrice  Total Volume        4046        4225      4770  \\\n",
       "51 2015-01-04          1.22      40873.28     2819.50    28287.42     49.90   \n",
       "51 2015-01-04          1.79       1373.95       57.42      153.88      0.00   \n",
       "51 2015-01-04          1.00     435021.49   364302.39    23821.16     82.15   \n",
       "51 2015-01-04          1.76       3846.69     1500.15      938.35      0.00   \n",
       "51 2015-01-04          1.08     788025.06    53987.31   552906.04  39995.03   \n",
       "..        ...           ...           ...         ...         ...       ...   \n",
       "14 2017-09-24          1.94    1125443.38   116338.61   237876.77   1182.85   \n",
       "14 2017-09-24          1.59    3842682.36  1450858.85  1006684.68  42995.08   \n",
       "14 2017-09-24          2.40     111321.19    17650.08    22295.44     42.34   \n",
       "14 2017-09-24          1.22     584045.70   363596.75    99990.28    415.70   \n",
       "14 2017-09-24          2.26       9528.64     1545.34     2234.23      0.00   \n",
       "\n",
       "    Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
       "51     9716.46     9186.93      529.53         0.00  conventional  2015   \n",
       "51     1162.65     1162.65        0.00         0.00       organic  2015   \n",
       "51    46815.79    16707.15    30108.64         0.00  conventional  2015   \n",
       "51     1408.19     1071.35      336.84         0.00       organic  2015   \n",
       "51   141136.68   137146.07     3990.61         0.00  conventional  2015   \n",
       "..         ...         ...         ...          ...           ...   ...   \n",
       "14   769536.90   639021.62   130401.43       113.85       organic  2017   \n",
       "14  1342143.75   764285.55   575719.82      2138.38  conventional  2017   \n",
       "14    71333.33    40018.26    31209.23       105.84       organic  2017   \n",
       "14   120042.97    68799.49    51236.81         6.67  conventional  2017   \n",
       "14     5749.07     5722.40       26.67         0.00       organic  2017   \n",
       "\n",
       "                 region  \n",
       "51               Albany  \n",
       "51               Albany  \n",
       "51              Atlanta  \n",
       "51              Atlanta  \n",
       "51  BaltimoreWashington  \n",
       "..                  ...  \n",
       "14              TotalUS  \n",
       "14                 West  \n",
       "14                 West  \n",
       "14     WestTexNewMexico  \n",
       "14     WestTexNewMexico  \n",
       "\n",
       "[15441 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting the dataframe by date \n",
    "\n",
    "date_sorted = df_train.sort_values([\"Date\", \"region\"])\n",
    "# region_sorted = df_train.sort_values(\"region\")\n",
    "date_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sorting by date we saw on the same date there are several measurements (several rows) hence there are multiple timeseries in our dataset. To further investigate, we sorted by the regions and saw on the same date and for the same date, there are two measurements based on the types. Therefore, we have a timeseries for each region and type of avocado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albany' 'Atlanta' 'BaltimoreWashington' 'Boise' 'Boston'\n",
      " 'BuffaloRochester' 'California' 'Charlotte' 'Chicago' 'CincinnatiDayton'\n",
      " 'Columbus' 'DallasFtWorth' 'Denver' 'Detroit' 'GrandRapids' 'GreatLakes'\n",
      " 'HarrisburgScranton' 'HartfordSpringfield' 'Houston' 'Indianapolis'\n",
      " 'Jacksonville' 'LasVegas' 'LosAngeles' 'Louisville' 'MiamiFtLauderdale'\n",
      " 'Midsouth' 'Nashville' 'NewOrleansMobile' 'NewYork' 'Northeast'\n",
      " 'NorthernNewEngland' 'Orlando' 'Philadelphia' 'PhoenixTucson'\n",
      " 'Pittsburgh' 'Plains' 'Portland' 'RaleighGreensboro' 'RichmondNorfolk'\n",
      " 'Roanoke' 'Sacramento' 'SanDiego' 'SanFrancisco' 'Seattle'\n",
      " 'SouthCarolina' 'SouthCentral' 'Southeast' 'Spokane' 'StLouis' 'Syracuse'\n",
      " 'Tampa' 'TotalUS' 'West' 'WestTexNewMexico']\n",
      "['conventional' 'organic']\n",
      "54\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(df_train[\"region\"].unique())\n",
    "print(df_train[\"type\"].unique())\n",
    "\n",
    "print(len(df_train[\"region\"].unique()))\n",
    "print(len(df_train[\"type\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  AveragePrice  Total Volume     4046       4225     4770  \\\n",
      "0  2015-12-27          1.33      64236.62  1036.74   54454.85    48.16   \n",
      "1  2015-12-20          1.35      54876.98   674.28   44638.81    58.33   \n",
      "2  2015-12-13          0.93     118220.22   794.70  109149.67   130.50   \n",
      "3  2015-12-06          1.08      78992.15  1132.00   71976.41    72.58   \n",
      "4  2015-11-29          1.28      51039.60   941.48   43838.39    75.78   \n",
      "..        ...           ...           ...      ...        ...      ...   \n",
      "48 2017-01-29          1.31      95424.59  3844.62   78315.15   484.56   \n",
      "49 2017-01-22          1.59     128679.24  4119.94  111173.08  2191.71   \n",
      "50 2017-01-15          1.55      88526.26  3327.65   71956.77   607.03   \n",
      "51 2017-01-08          1.55      91728.18  3355.47   75641.23    56.91   \n",
      "52 2017-01-01          1.47     129948.23  4845.77  117027.41   200.36   \n",
      "\n",
      "    Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
      "0      8696.87     8603.62       93.25         0.00  conventional  2015   \n",
      "1      9505.56     9408.07       97.49         0.00  conventional  2015   \n",
      "2      8145.35     8042.21      103.14         0.00  conventional  2015   \n",
      "3      5811.16     5677.40      133.76         0.00  conventional  2015   \n",
      "4      6183.95     5986.26      197.69         0.00  conventional  2015   \n",
      "..         ...         ...         ...          ...           ...   ...   \n",
      "48    12780.26    12393.84      382.06         4.36  conventional  2017   \n",
      "49    11194.51    11060.19      125.50         8.82  conventional  2017   \n",
      "50    12634.81    12574.72       60.09         0.00  conventional  2017   \n",
      "51    12674.57    12606.67       67.90         0.00  conventional  2017   \n",
      "52     7874.69     7866.86        7.83         0.00  conventional  2017   \n",
      "\n",
      "    region  \n",
      "0   Albany  \n",
      "1   Albany  \n",
      "2   Albany  \n",
      "3   Albany  \n",
      "4   Albany  \n",
      "..     ...  \n",
      "48  Albany  \n",
      "49  Albany  \n",
      "50  Albany  \n",
      "51  Albany  \n",
      "52  Albany  \n",
      "\n",
      "[143 rows x 13 columns]\n",
      "         Date  AveragePrice  Total Volume   4046    4225  4770  Total Bags  \\\n",
      "0  2015-12-27          1.83        989.55   8.16   88.59   0.0      892.80   \n",
      "1  2015-12-20          1.89       1163.03  30.24  172.14   0.0      960.65   \n",
      "2  2015-12-13          1.85        995.96  10.44  178.70   0.0      806.82   \n",
      "3  2015-12-06          1.84       1158.42  90.29  104.18   0.0      963.95   \n",
      "4  2015-11-29          1.94        831.69   0.00   94.73   0.0      736.96   \n",
      "..        ...           ...           ...    ...     ...   ...         ...   \n",
      "48 2017-01-29          1.86       1795.81  32.53  123.14   0.0     1640.14   \n",
      "49 2017-01-22          1.82       1897.07  78.83  128.24   0.0     1690.00   \n",
      "50 2017-01-15          1.84       1982.65  82.30  328.02   0.0     1572.33   \n",
      "51 2017-01-08          1.94       2229.52  63.46  478.31   0.0     1687.75   \n",
      "52 2017-01-01          1.87       1376.70  71.65  192.63   0.0     1112.42   \n",
      "\n",
      "    Small Bags  Large Bags  XLarge Bags     type  year  region  \n",
      "0       892.80        0.00          0.0  organic  2015  Albany  \n",
      "1       960.65        0.00          0.0  organic  2015  Albany  \n",
      "2       806.82        0.00          0.0  organic  2015  Albany  \n",
      "3       948.52       15.43          0.0  organic  2015  Albany  \n",
      "4       736.96        0.00          0.0  organic  2015  Albany  \n",
      "..         ...         ...          ...      ...   ...     ...  \n",
      "48     1640.14        0.00          0.0  organic  2017  Albany  \n",
      "49     1690.00        0.00          0.0  organic  2017  Albany  \n",
      "50     1572.33        0.00          0.0  organic  2017  Albany  \n",
      "51     1687.75        0.00          0.0  organic  2017  Albany  \n",
      "52     1112.42        0.00          0.0  organic  2017  Albany  \n",
      "\n",
      "[143 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exploring how many regions we have in the dataset and further exploring the different time series\n",
    "\n",
    "albany = df_train[df_train[\"region\"] == \"Albany\"]\n",
    "albany_conven = albany[albany[\"type\"] == \"conventional\"]\n",
    "albany_organic = albany[albany[\"type\"] == \"organic\"]\n",
    "\n",
    "print(albany_conven)\n",
    "print(albany_organic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>0.99</td>\n",
       "      <td>386100.49</td>\n",
       "      <td>292097.36</td>\n",
       "      <td>27350.92</td>\n",
       "      <td>297.90</td>\n",
       "      <td>66354.31</td>\n",
       "      <td>48605.95</td>\n",
       "      <td>17748.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.17</td>\n",
       "      <td>596819.40</td>\n",
       "      <td>40450.49</td>\n",
       "      <td>394104.02</td>\n",
       "      <td>17353.79</td>\n",
       "      <td>144911.10</td>\n",
       "      <td>142543.88</td>\n",
       "      <td>2367.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>BaltimoreWashington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>0.97</td>\n",
       "      <td>62909.69</td>\n",
       "      <td>30482.25</td>\n",
       "      <td>2971.94</td>\n",
       "      <td>5894.40</td>\n",
       "      <td>23561.10</td>\n",
       "      <td>23520.19</td>\n",
       "      <td>5.69</td>\n",
       "      <td>35.22</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Boise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.13</td>\n",
       "      <td>450816.39</td>\n",
       "      <td>3886.27</td>\n",
       "      <td>346964.70</td>\n",
       "      <td>13952.56</td>\n",
       "      <td>86012.86</td>\n",
       "      <td>85913.60</td>\n",
       "      <td>99.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1652.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1578.97</td>\n",
       "      <td>1336.27</td>\n",
       "      <td>242.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>Syracuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2161.84</td>\n",
       "      <td>874.75</td>\n",
       "      <td>17.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1269.55</td>\n",
       "      <td>1216.67</td>\n",
       "      <td>52.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>Tampa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.52</td>\n",
       "      <td>549787.59</td>\n",
       "      <td>89709.92</td>\n",
       "      <td>206198.62</td>\n",
       "      <td>5836.04</td>\n",
       "      <td>248043.01</td>\n",
       "      <td>142262.93</td>\n",
       "      <td>105780.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>TotalUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.46</td>\n",
       "      <td>142710.36</td>\n",
       "      <td>29880.32</td>\n",
       "      <td>48416.71</td>\n",
       "      <td>38.63</td>\n",
       "      <td>64374.70</td>\n",
       "      <td>17464.54</td>\n",
       "      <td>46910.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.81</td>\n",
       "      <td>7155.63</td>\n",
       "      <td>1478.79</td>\n",
       "      <td>2629.64</td>\n",
       "      <td>14.10</td>\n",
       "      <td>3033.10</td>\n",
       "      <td>2855.55</td>\n",
       "      <td>177.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>organic</td>\n",
       "      <td>2015</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  AveragePrice  Total Volume       4046       4225      4770  \\\n",
       "0  2015-12-27          1.33      64236.62    1036.74   54454.85     48.16   \n",
       "0  2015-12-27          0.99     386100.49  292097.36   27350.92    297.90   \n",
       "0  2015-12-27          1.17     596819.40   40450.49  394104.02  17353.79   \n",
       "0  2015-12-27          0.97      62909.69   30482.25    2971.94   5894.40   \n",
       "0  2015-12-27          1.13     450816.39    3886.27  346964.70  13952.56   \n",
       "..        ...           ...           ...        ...        ...       ...   \n",
       "0  2015-12-27          1.54       1652.19       0.00      73.22      0.00   \n",
       "0  2015-12-27          1.63       2161.84     874.75      17.54      0.00   \n",
       "0  2015-12-27          1.52     549787.59   89709.92  206198.62   5836.04   \n",
       "0  2015-12-27          1.46     142710.36   29880.32   48416.71     38.63   \n",
       "0  2015-12-27          1.81       7155.63    1478.79    2629.64     14.10   \n",
       "\n",
       "    Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
       "0      8696.87     8603.62       93.25         0.00  conventional  2015   \n",
       "0     66354.31    48605.95    17748.36         0.00  conventional  2015   \n",
       "0    144911.10   142543.88     2367.22         0.00  conventional  2015   \n",
       "0     23561.10    23520.19        5.69        35.22  conventional  2015   \n",
       "0     86012.86    85913.60       99.26         0.00  conventional  2015   \n",
       "..         ...         ...         ...          ...           ...   ...   \n",
       "0      1578.97     1336.27      242.70         0.00       organic  2015   \n",
       "0      1269.55     1216.67       52.88         0.00       organic  2015   \n",
       "0    248043.01   142262.93   105780.08         0.00       organic  2015   \n",
       "0     64374.70    17464.54    46910.16         0.00       organic  2015   \n",
       "0      3033.10     2855.55      177.55         0.00       organic  2015   \n",
       "\n",
       "                 region  \n",
       "0                Albany  \n",
       "0               Atlanta  \n",
       "0   BaltimoreWashington  \n",
       "0                 Boise  \n",
       "0                Boston  \n",
       "..                  ...  \n",
       "0              Syracuse  \n",
       "0                 Tampa  \n",
       "0               TotalUS  \n",
       "0                  West  \n",
       "0      WestTexNewMexico  \n",
       "\n",
       "[108 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[\"Date\"] == \"2015-12-27\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our analysis, we picked the first date from the dataframe. For this particular date we can there are 108 different points. Inspecting these 108 points we can see that each pair of type and region has a different time series associated with it. This is supported by the fact that we have 54 unique regions and 2 unique types, giving us 108 pairs of region and type combinations. Overall, we have 108 timeseries in our data, for the two categorical variables - region and type.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.2 Equally spaced measurements? \n",
    "rubric={points:4}\n",
    "\n",
    "In the Rain in Australia dataset, the measurements were generally equally spaced but with some exceptions. How about with this dataset? Justify your answer by referencing the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze spacing, we iteratively went through each region and type combination. \n",
    "From the results we can see that only WestTexNewMexico and organic type has an irregularly spaced data. \n",
    "\n",
    "They also had 140 rows compared to all region and type that has 143 rows.  \n",
    "Specifically, as shown below, the dates betweeen 2015-11-29 and 2015-12-13 is irregularly spaced compared to all other time points, and also 2017-06-11 and 2017-07-02 are also irregular compared to all other time points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2015-12-27\n",
       "1    2015-12-20\n",
       "2    2015-12-13\n",
       "3    2015-12-06\n",
       "4    2015-11-29\n",
       "        ...    \n",
       "46   2017-01-29\n",
       "47   2017-01-22\n",
       "48   2017-01-15\n",
       "49   2017-01-08\n",
       "50   2017-01-01\n",
       "Name: Date, Length: 15441, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-12-13T00:00:00.000000000\n",
      "48\n",
      "2017-07-02T00:00:00.000000000\n",
      "127\n",
      "WestTexNewMexico organic\n",
      "140\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# temp = df_train[np.logical_and(df_train[\"region\"] == \"Albany\", df_train[\"type\"] == \"conventional\")]\n",
    "# dates = np.sort(temp[\"Date\"])\n",
    "# prev = dates[0]\n",
    "# diff = []\n",
    "# for i in range(len(dates)):\n",
    "#     diff.append(dates[i] - prev)\n",
    "#     prev = dates[i]\n",
    "# # diff = diff[1:]\n",
    "# # print(len(set(diff)) == 1)\n",
    "\n",
    "# print(len(diff))\n",
    "result = []\n",
    "\n",
    "for region in df_train[\"region\"].unique():\n",
    "    for tp in df_train[\"type\"].unique():\n",
    "        temp = df_train[np.logical_and(df_train[\"region\"] == region, df_train[\"type\"] == tp)]\n",
    "        dates = np.sort(temp[\"Date\"])\n",
    "        prev = dates[0]\n",
    "        diff = []\n",
    "        for i in range(1, len(dates)):\n",
    "            day = (dates[i] - prev)\n",
    "            diff.append(day.astype(int))\n",
    "            prev = dates[i]\n",
    "            \n",
    "            if day != diff[0]:\n",
    "                print(dates[i])\n",
    "                print(i)\n",
    "                \n",
    "        result.append(len(set(diff)) == 1)\n",
    "        if (len(set(diff)) == 1) == False:\n",
    "            print(region, tp)\n",
    "            print(len(temp))\n",
    "print(all(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  AveragePrice  Total Volume     4046     4225  4770  Total Bags  \\\n",
      "47 2015-01-25          1.63       7324.06  1934.46  3032.72   0.0     2356.88   \n",
      "48 2015-01-18          1.71       5508.20  1793.64  2078.72   0.0     1635.84   \n",
      "\n",
      "    Small Bags  Large Bags  XLarge Bags     type  year            region  \n",
      "47      2320.0       36.88          0.0  organic  2015  WestTexNewMexico  \n",
      "48      1620.0       15.84          0.0  organic  2015  WestTexNewMexico  \n",
      "         Date  AveragePrice  Total Volume     4046     4225   4770  \\\n",
      "37 2017-04-02          1.04      28803.50  2551.72  2586.16  11.61   \n",
      "38 2017-03-26          1.11      32073.43  3041.33  3451.21  66.76   \n",
      "39 2017-03-19          1.11      26767.63  4255.75  3855.69  11.67   \n",
      "\n",
      "    Total Bags  Small Bags  Large Bags  XLarge Bags     type  year  \\\n",
      "37    23654.01    23267.01      387.00          0.0  organic  2017   \n",
      "38    25514.13    25191.62      322.51          0.0  organic  2017   \n",
      "39    18644.52    13278.06     5366.46          0.0  organic  2017   \n",
      "\n",
      "              region  \n",
      "37  WestTexNewMexico  \n",
      "38  WestTexNewMexico  \n",
      "39  WestTexNewMexico  \n"
     ]
    }
   ],
   "source": [
    "temp_df = df_train[np.logical_and(df_train[\"region\"] == \"WestTexNewMexico\", df_train[\"type\"] == \"organic\")]\n",
    "print(temp_df[47:49])\n",
    "print(temp_df[126:129])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WestTexNewMexico\n",
      "organic\n",
      "[143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 143, 140]\n"
     ]
    }
   ],
   "source": [
    "# Checking number of rows for all other region and type \n",
    "\n",
    "len_ts = []\n",
    "for region in df_train[\"region\"].unique():\n",
    "    for tp in df_train[\"type\"].unique():\n",
    "        length = len(df_train[np.logical_and(df_train[\"region\"] == region, df_train[\"type\"] == tp)])\n",
    "        len_ts.append(length)\n",
    "        \n",
    "        if length != len_ts[0]:\n",
    "            print(region)\n",
    "            print(tp)\n",
    "\n",
    "print(len_ts)\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.3 Interpreting regions \n",
    "rubric={points:4}\n",
    "\n",
    "In the Rain is Australia dataset, each location was a different place in Australia. For this dataset, look at the names of the regions. Do you think the regions are also all distinct, or are there overlapping regions? Justify your answer by referencing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albany' 'Atlanta' 'BaltimoreWashington' 'Boise' 'Boston'\n",
      " 'BuffaloRochester' 'California' 'Charlotte' 'Chicago' 'CincinnatiDayton'\n",
      " 'Columbus' 'DallasFtWorth' 'Denver' 'Detroit' 'GrandRapids' 'GreatLakes'\n",
      " 'HarrisburgScranton' 'HartfordSpringfield' 'Houston' 'Indianapolis'\n",
      " 'Jacksonville' 'LasVegas' 'LosAngeles' 'Louisville' 'MiamiFtLauderdale'\n",
      " 'Midsouth' 'Nashville' 'NewOrleansMobile' 'NewYork' 'Northeast'\n",
      " 'NorthernNewEngland' 'Orlando' 'Philadelphia' 'PhoenixTucson'\n",
      " 'Pittsburgh' 'Plains' 'Portland' 'RaleighGreensboro' 'RichmondNorfolk'\n",
      " 'Roanoke' 'Sacramento' 'SanDiego' 'SanFrancisco' 'Seattle'\n",
      " 'SouthCarolina' 'SouthCentral' 'Southeast' 'Spokane' 'StLouis' 'Syracuse'\n",
      " 'Tampa' 'TotalUS' 'West' 'WestTexNewMexico']\n"
     ]
    }
   ],
   "source": [
    "print((df_train[\"region\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "While most of the entries in \"region\" are cities, there are a few exceptions such as \"California\", \"SouthCarolina\", and \"Northeast\" that are states and larger geographical area. These exceptions overlap with other cities, for example \"California\" overlaps with 'SanDiego', 'SanFrancisco', and other cities in the state of California. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the entire dataset despite any location-based weirdness uncovered in the previous part.\n",
    "\n",
    "We will be trying to forecast the avocado price. The function below is adapted from Lecture 20, with some improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_feature(df, orig_feature, lag, groupby, new_feature_name=None, clip=False):\n",
    "    \"\"\"\n",
    "    Creates a new feature that's a lagged version of an existing one.\n",
    "    \n",
    "    NOTE: assumes df is already sorted by the time columns and has unique indices.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        The dataset.\n",
    "    orig_feature : str\n",
    "        The column name of the feature we're copying\n",
    "    lag : int\n",
    "        The lag; negative lag means values from the past, positive lag means values from the future\n",
    "    groupby : list\n",
    "        Column(s) to group by in case df contains multiple time series\n",
    "    new_feature_name : str\n",
    "        Override the default name of the newly created column\n",
    "    clip : bool\n",
    "        If True, remove rows with a NaN values for the new feature\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.core.frame.DataFrame\n",
    "        A new dataframe with the additional column added.\n",
    "        \n",
    "    TODO: could/should simplify this function by using `df.shift()`\n",
    "    \"\"\"\n",
    "        \n",
    "    if new_feature_name is None:\n",
    "        if lag < 0:\n",
    "            new_feature_name = \"%s_lag%d\" % (orig_feature, -lag)\n",
    "        else:\n",
    "            new_feature_name = \"%s_ahead%d\" % (orig_feature, lag)\n",
    "    \n",
    "    new_df = df.assign(**{new_feature_name : np.nan})\n",
    "    for name, group in new_df.groupby(groupby):        \n",
    "        if lag < 0: # take values from the past\n",
    "            new_df.loc[group.index[-lag:],new_feature_name] = group.iloc[:lag][orig_feature].values\n",
    "        else:       # take values from the future\n",
    "            new_df.loc[group.index[:-lag], new_feature_name] = group.iloc[lag:][orig_feature].values\n",
    "            \n",
    "    if clip:\n",
    "        new_df = new_df.dropna(subset=[new_feature_name])\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first sort our dataframe properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.22</td>\n",
       "      <td>40873.28</td>\n",
       "      <td>2819.50</td>\n",
       "      <td>28287.42</td>\n",
       "      <td>49.90</td>\n",
       "      <td>9716.46</td>\n",
       "      <td>9186.93</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>1.24</td>\n",
       "      <td>41195.08</td>\n",
       "      <td>1002.85</td>\n",
       "      <td>31640.34</td>\n",
       "      <td>127.12</td>\n",
       "      <td>8424.77</td>\n",
       "      <td>8036.04</td>\n",
       "      <td>388.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>1.17</td>\n",
       "      <td>44511.28</td>\n",
       "      <td>914.14</td>\n",
       "      <td>31540.32</td>\n",
       "      <td>135.77</td>\n",
       "      <td>11921.05</td>\n",
       "      <td>11651.09</td>\n",
       "      <td>269.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>1.06</td>\n",
       "      <td>45147.50</td>\n",
       "      <td>941.38</td>\n",
       "      <td>33196.16</td>\n",
       "      <td>164.14</td>\n",
       "      <td>10845.82</td>\n",
       "      <td>10103.35</td>\n",
       "      <td>742.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>70873.60</td>\n",
       "      <td>1353.90</td>\n",
       "      <td>60017.20</td>\n",
       "      <td>179.32</td>\n",
       "      <td>9323.18</td>\n",
       "      <td>9170.82</td>\n",
       "      <td>152.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18244</th>\n",
       "      <td>2018-02-25</td>\n",
       "      <td>1.57</td>\n",
       "      <td>18421.24</td>\n",
       "      <td>1974.26</td>\n",
       "      <td>2482.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13964.33</td>\n",
       "      <td>13698.27</td>\n",
       "      <td>266.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18245</th>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>1.54</td>\n",
       "      <td>17393.30</td>\n",
       "      <td>1832.24</td>\n",
       "      <td>1905.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13655.49</td>\n",
       "      <td>13401.93</td>\n",
       "      <td>253.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>1.56</td>\n",
       "      <td>22128.42</td>\n",
       "      <td>2162.67</td>\n",
       "      <td>3194.25</td>\n",
       "      <td>8.93</td>\n",
       "      <td>16762.57</td>\n",
       "      <td>16510.32</td>\n",
       "      <td>252.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>1.56</td>\n",
       "      <td>15896.38</td>\n",
       "      <td>2055.35</td>\n",
       "      <td>1499.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12341.48</td>\n",
       "      <td>12114.81</td>\n",
       "      <td>226.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18248</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>1.62</td>\n",
       "      <td>15303.40</td>\n",
       "      <td>2325.30</td>\n",
       "      <td>2171.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10806.44</td>\n",
       "      <td>10569.80</td>\n",
       "      <td>236.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18249 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  AveragePrice  Total Volume     4046      4225    4770  \\\n",
       "0     2015-01-04          1.22      40873.28  2819.50  28287.42   49.90   \n",
       "1     2015-01-11          1.24      41195.08  1002.85  31640.34  127.12   \n",
       "2     2015-01-18          1.17      44511.28   914.14  31540.32  135.77   \n",
       "3     2015-01-25          1.06      45147.50   941.38  33196.16  164.14   \n",
       "4     2015-02-01          0.99      70873.60  1353.90  60017.20  179.32   \n",
       "...          ...           ...           ...      ...       ...     ...   \n",
       "18244 2018-02-25          1.57      18421.24  1974.26   2482.65    0.00   \n",
       "18245 2018-03-04          1.54      17393.30  1832.24   1905.57    0.00   \n",
       "18246 2018-03-11          1.56      22128.42  2162.67   3194.25    8.93   \n",
       "18247 2018-03-18          1.56      15896.38  2055.35   1499.55    0.00   \n",
       "18248 2018-03-25          1.62      15303.40  2325.30   2171.66    0.00   \n",
       "\n",
       "       Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
       "0         9716.46     9186.93      529.53          0.0  conventional  2015   \n",
       "1         8424.77     8036.04      388.73          0.0  conventional  2015   \n",
       "2        11921.05    11651.09      269.96          0.0  conventional  2015   \n",
       "3        10845.82    10103.35      742.47          0.0  conventional  2015   \n",
       "4         9323.18     9170.82      152.36          0.0  conventional  2015   \n",
       "...           ...         ...         ...          ...           ...   ...   \n",
       "18244    13964.33    13698.27      266.06          0.0       organic  2018   \n",
       "18245    13655.49    13401.93      253.56          0.0       organic  2018   \n",
       "18246    16762.57    16510.32      252.25          0.0       organic  2018   \n",
       "18247    12341.48    12114.81      226.67          0.0       organic  2018   \n",
       "18248    10806.44    10569.80      236.64          0.0       organic  2018   \n",
       "\n",
       "                 region  \n",
       "0                Albany  \n",
       "1                Albany  \n",
       "2                Albany  \n",
       "3                Albany  \n",
       "4                Albany  \n",
       "...                 ...  \n",
       "18244  WestTexNewMexico  \n",
       "18245  WestTexNewMexico  \n",
       "18246  WestTexNewMexico  \n",
       "18247  WestTexNewMexico  \n",
       "18248  WestTexNewMexico  \n",
       "\n",
       "[18249 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sort = df.sort_values(by=[\"region\", \"type\", \"Date\"]).reset_index(drop=True)\n",
    "df_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then call `create_lag_feature`. This creates a new column in the dataset `AveragePriceNextWeek`, which is the following week's `AveragePrice`. We have set `clip=True` which means it will remove rows where the target would be missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>AveragePriceNextWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1.22</td>\n",
       "      <td>40873.28</td>\n",
       "      <td>2819.50</td>\n",
       "      <td>28287.42</td>\n",
       "      <td>49.90</td>\n",
       "      <td>9716.46</td>\n",
       "      <td>9186.93</td>\n",
       "      <td>529.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>1.24</td>\n",
       "      <td>41195.08</td>\n",
       "      <td>1002.85</td>\n",
       "      <td>31640.34</td>\n",
       "      <td>127.12</td>\n",
       "      <td>8424.77</td>\n",
       "      <td>8036.04</td>\n",
       "      <td>388.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>1.17</td>\n",
       "      <td>44511.28</td>\n",
       "      <td>914.14</td>\n",
       "      <td>31540.32</td>\n",
       "      <td>135.77</td>\n",
       "      <td>11921.05</td>\n",
       "      <td>11651.09</td>\n",
       "      <td>269.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>1.06</td>\n",
       "      <td>45147.50</td>\n",
       "      <td>941.38</td>\n",
       "      <td>33196.16</td>\n",
       "      <td>164.14</td>\n",
       "      <td>10845.82</td>\n",
       "      <td>10103.35</td>\n",
       "      <td>742.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>70873.60</td>\n",
       "      <td>1353.90</td>\n",
       "      <td>60017.20</td>\n",
       "      <td>179.32</td>\n",
       "      <td>9323.18</td>\n",
       "      <td>9170.82</td>\n",
       "      <td>152.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18243</th>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>1.56</td>\n",
       "      <td>17597.12</td>\n",
       "      <td>1892.05</td>\n",
       "      <td>1928.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13776.71</td>\n",
       "      <td>13553.53</td>\n",
       "      <td>223.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18244</th>\n",
       "      <td>2018-02-25</td>\n",
       "      <td>1.57</td>\n",
       "      <td>18421.24</td>\n",
       "      <td>1974.26</td>\n",
       "      <td>2482.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13964.33</td>\n",
       "      <td>13698.27</td>\n",
       "      <td>266.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18245</th>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>1.54</td>\n",
       "      <td>17393.30</td>\n",
       "      <td>1832.24</td>\n",
       "      <td>1905.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13655.49</td>\n",
       "      <td>13401.93</td>\n",
       "      <td>253.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>1.56</td>\n",
       "      <td>22128.42</td>\n",
       "      <td>2162.67</td>\n",
       "      <td>3194.25</td>\n",
       "      <td>8.93</td>\n",
       "      <td>16762.57</td>\n",
       "      <td>16510.32</td>\n",
       "      <td>252.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>1.56</td>\n",
       "      <td>15896.38</td>\n",
       "      <td>2055.35</td>\n",
       "      <td>1499.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12341.48</td>\n",
       "      <td>12114.81</td>\n",
       "      <td>226.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18141 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  AveragePrice  Total Volume     4046      4225    4770  \\\n",
       "0     2015-01-04          1.22      40873.28  2819.50  28287.42   49.90   \n",
       "1     2015-01-11          1.24      41195.08  1002.85  31640.34  127.12   \n",
       "2     2015-01-18          1.17      44511.28   914.14  31540.32  135.77   \n",
       "3     2015-01-25          1.06      45147.50   941.38  33196.16  164.14   \n",
       "4     2015-02-01          0.99      70873.60  1353.90  60017.20  179.32   \n",
       "...          ...           ...           ...      ...       ...     ...   \n",
       "18243 2018-02-18          1.56      17597.12  1892.05   1928.36    0.00   \n",
       "18244 2018-02-25          1.57      18421.24  1974.26   2482.65    0.00   \n",
       "18245 2018-03-04          1.54      17393.30  1832.24   1905.57    0.00   \n",
       "18246 2018-03-11          1.56      22128.42  2162.67   3194.25    8.93   \n",
       "18247 2018-03-18          1.56      15896.38  2055.35   1499.55    0.00   \n",
       "\n",
       "       Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
       "0         9716.46     9186.93      529.53          0.0  conventional  2015   \n",
       "1         8424.77     8036.04      388.73          0.0  conventional  2015   \n",
       "2        11921.05    11651.09      269.96          0.0  conventional  2015   \n",
       "3        10845.82    10103.35      742.47          0.0  conventional  2015   \n",
       "4         9323.18     9170.82      152.36          0.0  conventional  2015   \n",
       "...           ...         ...         ...          ...           ...   ...   \n",
       "18243    13776.71    13553.53      223.18          0.0       organic  2018   \n",
       "18244    13964.33    13698.27      266.06          0.0       organic  2018   \n",
       "18245    13655.49    13401.93      253.56          0.0       organic  2018   \n",
       "18246    16762.57    16510.32      252.25          0.0       organic  2018   \n",
       "18247    12341.48    12114.81      226.67          0.0       organic  2018   \n",
       "\n",
       "                 region  AveragePriceNextWeek  \n",
       "0                Albany                  1.24  \n",
       "1                Albany                  1.17  \n",
       "2                Albany                  1.06  \n",
       "3                Albany                  0.99  \n",
       "4                Albany                  0.99  \n",
       "...                 ...                   ...  \n",
       "18243  WestTexNewMexico                  1.57  \n",
       "18244  WestTexNewMexico                  1.54  \n",
       "18245  WestTexNewMexico                  1.56  \n",
       "18246  WestTexNewMexico                  1.56  \n",
       "18247  WestTexNewMexico                  1.62  \n",
       "\n",
       "[18141 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hastarget = create_lag_feature(df_sort, \"AveragePrice\", +1, [\"region\", \"type\"], \"AveragePriceNextWeek\", clip=True)\n",
    "df_hastarget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to predict `AveragePriceNextWeek`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_hastarget[df_hastarget[\"Date\"] <= split_date]\n",
    "df_test  = df_hastarget[df_hastarget[\"Date\"] >  split_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.4 `AveragePrice` baseline \n",
    "rubric={points:4}\n",
    "\n",
    "Soon we will want to build some models to forecast the average avocado price a week in advance. Before we start with any ML though, let's try a baseline. Previously we used `DummyClassifier` or `DummyRegressor` as a baseline. This time, we'll do something else as a baseline: we'll assume the price stays the same from this week to next week. So, we'll set our prediction of \"AveragePriceNextWeek\" exactly equal to \"AveragePrice\", assuming no change. That is kind of like saying, \"If it's raining today then I'm guessing it will be raining tomorrow\". This simplistic approach will not get a great score but it's a good starting point for reference. If our model does worse that this, it must not be very good. \n",
    "\n",
    "Using this baseline approach, what $R^2$ do you get on the train and test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.4\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8285800937261841"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating R2 on training data \n",
    "r2_score(df_train[\"AveragePriceNextWeek\"], df_train[\"AveragePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7631780188583048"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating R2 on testing data \n",
    "r2_score(df_test[\"AveragePriceNextWeek\"], df_test[\"AveragePrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.5 Forecasting average avocado price\n",
    "rubric={points:10}\n",
    "\n",
    "Now that the baseline is done, let's build some models to forecast the average avocado price a week later. Experiment with a few approachs for encoding the date. Justify the decisions you make. Which approach worked best? Report your test score and briefly discuss your results.\n",
    "\n",
    "Benchmark: you should be able to achieve $R^2$ of at least 0.79 on the test set. I got to 0.80, but not beyond that. Let me know if you do better!\n",
    "\n",
    "Note: because we only have 2 splits here, we need to be a bit wary of overfitting on the test set. Try not to test on it a ridiculous number of times. If you are interested in some proper ways of dealing with this, see for example sklearn's [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html), which is like cross-validation for time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(month):\n",
    "    SUMMER_MONTHS = [\"June\", \"July\", \"August\"] \n",
    "    SPRING_MONTHS = [\"March\", \"April\", \"May\"]\n",
    "    WINTER_MONTHS = [\"December\", \"January\", \"February\"]\n",
    "    AUTUMN_MONTHS = [\"September\", \"October\", \"November\"]\n",
    "    if month in WINTER_MONTHS:\n",
    "        return \"Winter\"\n",
    "    elif month in AUTUMN_MONTHS:\n",
    "        return \"Autumn\"\n",
    "    elif month in SUMMER_MONTHS:\n",
    "        return \"Summer\"\n",
    "    else:\n",
    "        return \"Fall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.assign(Month=df_train[\"Date\"].apply(lambda x: x.month_name()))\n",
    "df_test = df_test.assign(Month=df_test[\"Date\"].apply(lambda x: x.month_name()))\n",
    "\n",
    "df_train = df_train.assign(Season=df_train[\"Date\"].apply(lambda x: get_season(x.month_name())))\n",
    "df_test = df_test.assign(Season=df_test[\"Date\"].apply(lambda x: get_season(x.month_name())))\n",
    "\n",
    "X_train = df_train.drop(columns= [\"AveragePriceNextWeek\"])\n",
    "y_train = df_train[\"AveragePriceNextWeek\"]\n",
    "X_test = df_test.drop(columns= [\"AveragePriceNextWeek\"])\n",
    "y_test = df_test[\"AveragePriceNextWeek\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"AveragePrice\", \"Total Volume\", \"4046\", \"4225\", \"4770\", \"Small Bags\", \"Large Bags\", \"XLarge Bags\"]\n",
    "categorical_features = [\"type\", \"year\", \"region\", \"Season\"]\n",
    "drop_features = [\"Date\",\"Month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\"), StandardScaler()\n",
    "    )\n",
    "categorical_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "        OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    "    )\n",
    "preprocessor = make_column_transformer(\n",
    "        (numeric_transformer, numeric_features),\n",
    "        (categorical_transformer, categorical_features),\n",
    "        (\"drop\", drop_features),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7937165719422217"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OHE on season\n",
    "pipe = make_pipeline(preprocessor, Ridge())\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_features = [\"type\", \"year\", \"region\", \"Month\"]\n",
    "drop_features = [\"Date\",\"Season\"]\n",
    "numeric_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\"), StandardScaler()\n",
    "    )\n",
    "categorical_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "        OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    "    )\n",
    "preprocessor = make_column_transformer(\n",
    "        (numeric_transformer, numeric_features),\n",
    "        (categorical_transformer, categorical_features),\n",
    "        (\"drop\", drop_features),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8018263014781949"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OHE on month\n",
    "pipe = make_pipeline(preprocessor, Ridge())\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We chose to approach the encoding of \"Date\" in two different ways: one hot encoding based on season and month. We hypothesized that the price of avocado might change based on season. Therefore, we performed feature engineering to extract seasons from the \"Date\" column. After OHE on season, which gave us the R^2 score of 0.79. We then tried OHE on month because we thought the price of avocado could also depend on individual month as opposed to grouping into seasons, and it did give us a little improvement with a R^2 of 0.80. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: very short answer questions\n",
    "\n",
    "Each question is worth 2 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.1 Time series\n",
    "\n",
    "rubric={points:4}\n",
    "\n",
    "The following questions pertain to Lecture 20 on time series data:\n",
    "\n",
    "1. Sometimes a time series has missing time points or, worse, time points that are unequally spaced in general. Give an example of a real world situation where the time series data would have unequally spaced time points.\n",
    "2. In class we discussed two approaches to using temporal information: encoding the date as one or more features, and creating lagged versions of features. Which of these (one/other/both/neither) two approaches would struggle with unequally spaced time points? Briefly justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 2.1.1\n",
    "\n",
    "Unequally spaced time points might occur due to various reasons: \n",
    "(1) a server might not be up all the time eg in case they need to be turned off for backing up so if the database with that server was recording transactions, it might have time points missing\n",
    "(2) during holidays markets might be closed so it is difficult to collect measurements for customers during those time points (for eg if the experiment is observing customer's behaviour)\n",
    "(3) if natural disasters are measured, they will be collected at irregularly spaced time points since they dont occur regularly (inspired by the https://en.wikipedia.org/wiki/Unevenly_spaced_time_series)\n",
    "\n",
    "\n",
    "### Answer 2.1.2\n",
    "\n",
    "Lag versions of feature approach have the most chance to suffer from unequally spaced time points. If data is missing or is unequally spaced in one of the original features, shifting the data points will run into issues of inaccuracy. For example in our avocado price, if a week is missing, we can no longer accurately calculate the \"Average Price Next Week\" feature for the previous week. Thus, we lose information or accuracy by trying to \"fix\" the unequally spaced time points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.2 Survival analysis\n",
    "rubric={points:6}\n",
    "\n",
    "The following questions pertain to Lecture 21 on survival analysis. We'll consider the use case of customer churn analysis.\n",
    "\n",
    "1. What is the problem with simply labeling customers are \"churned\" or \"not churned\" and using standard supervised learning techniques?\n",
    "2. Consider customer A who just joined last week vs. customer B who has been with the service for a year. Who do you expect will leave the service first: probably customer A, probably customer B, or we don't have enough information to answer?\n",
    "3. If a customer's survival function is almost flat during a certain period, how do we interpret that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 2.2.1\n",
    "\n",
    "We don't know whether the customer will churn after the collection period ends, so we cannot label it churned/not churned. Our output in these problems are right censored ie we donot know the customers churning or not churning after the study ends which restricts us from using standard supervised machine learning techniques. If all customers are labelled as churned at the end, our analysis will overestimate churning within that time and if all customers are labelled as not churned at the end, our analysis will overestimate not churning. \n",
    "Hence our main issue is that we donot know information on customers once the study collection period ends.\n",
    "\n",
    "### Answer 2.2.2\n",
    "\n",
    "According to the general survival probability vs time plot we saw in lecture, there is a high chance that a customer who has been with the service for long has a higher chance of churning since generally as time increases survival chances decreases. However, we need more information to analyze individual Customer behaviour since we need more demographic information from the individual person. For example - someone who just joined might be on a free trial (Customer A) vs a loyal customer (like customer B) so the person who joined recently might leave soon after the free trial ends. Conversely, someone who has been with the service for a long time might have their membership with the service ending soon vs who joined just now might have bought a year long membership so then Customer B will have higher chance of leaving. \n",
    "\n",
    "Thus we donot have enough information for a confirmed answer\n",
    "\n",
    "### Answer 2.2.3\n",
    "\n",
    "It means their survival probability does not change during that time period. Thus it can be interpreted that for the almost flat region of time, the customer has little chance of leaving.\n",
    "For example, the time period here could be duration of their membership with the service and so the flat curve can show that once a customer buys a membership with the service, they will stay with the service for the entire duration of their membership. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Code used in Q1 was referenced from lecture on time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLEASE READ BEFORE YOU SUBMIT:** \n",
    "\n",
    "When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from \"1\" will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. \n",
    "4. Make sure that the plots and output are rendered properly in your submitted file. If the .ipynb file is too big and doesn't render on Gradescope, also upload a pdf or html in addition to the .ipynb so that the TAs can view your submission on Gradescope. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/eva-well-done.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "name": "_merged",
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "438px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
